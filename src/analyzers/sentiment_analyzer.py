"""
ë‰´ìŠ¤ ë° í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„ ëª¨ë“ˆ
Phase F: LLMSentimentAnalyzer (Gemini) í†µí•©
"""
from typing import List, Dict, Optional
import re

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except ImportError:
    TEXTBLOB_AVAILABLE = False

try:
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VaderAnalyzer
    VADER_AVAILABLE = True
except ImportError:
    VADER_AVAILABLE = False

# Phase F: LLM Sentiment Analyzer (Gemini)
try:
    from src.infrastructure.sentiment.llm_sentiment_analyzer import LLMSentimentAnalyzer
    LLM_SENTIMENT_AVAILABLE = True
except ImportError:
    LLM_SENTIMENT_AVAILABLE = False

class SentimentAnalyzer:
    """
    í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„ê¸°
    
    ì§€ì› ëª¨ë“œ:
    - ê¸°ë³¸: í‚¤ì›Œë“œ + TextBlob
    - ë”¥ëŸ¬ë‹: KR-FinBert-SC
    - LLM: Gemini API (Phase F)
    """
    
    def __init__(self, use_deep_learning: bool = False, use_llm: bool = False):
        """
        ì´ˆê¸°í™”
        Args:
            use_deep_learning: ë”¥ëŸ¬ë‹ ëª¨ë¸(FinBERT) ì‚¬ìš© ì—¬ë¶€
            use_llm: Gemini LLM ê°ì„± ë¶„ì„ ì‚¬ìš© ì—¬ë¶€ (Phase F)
        """
        self.use_deep_learning = use_deep_learning
        self.use_llm = use_llm
        self.dl_model = None
        self.dl_tokenizer = None
        self.dl_pipeline = None
        self.vader_analyzer = None
        self.llm_analyzer = None
        
        # VADER ë¶„ì„ê¸° ì´ˆê¸°í™” (ì˜ë¬¸ìš©)
        if VADER_AVAILABLE:
            self.vader_analyzer = VaderAnalyzer()
        
        # LLM ë¶„ì„ê¸° ì´ˆê¸°í™” (Gemini) - ì¤‘ì•™í™”ëœ API í‚¤ ì‚¬ìš©
        if use_llm and LLM_SENTIMENT_AVAILABLE:
            try:
                # Phase F: ì¤‘ì•™í™”ëœ API í‚¤ ì‚¬ìš© (LLMClientFactory)
                from src.infrastructure.external.llm_client_factory import LLMClientFactory
                gemini_client = LLMClientFactory.create_gemini_client()
                
                # GeminiClientì¸ì§€ í™•ì¸ (MockLLMClientê°€ ì•„ë‹Œì§€)
                from src.infrastructure.external.gemini_client import GeminiClient
                if isinstance(gemini_client, GeminiClient) and gemini_client.is_available():
                    self.llm_analyzer = LLMSentimentAnalyzer(llm_client=gemini_client)
                    print("[INFO] Gemini LLM ê°ì„± ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    print("[WARNING] Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°” 'ğŸ”‘ AI API ì„¤ì •'ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    self.use_llm = False
            except Exception as e:
                print(f"[WARNING] LLM ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. ê¸°ë³¸ ë¶„ì„ ì‚¬ìš©.")
                self.use_llm = False
        elif use_llm and not LLM_SENTIMENT_AVAILABLE:
            print("[WARNING] LLMSentimentAnalyzerë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ ì‚¬ìš©.")
            self.use_llm = False
        
        if use_deep_learning:
            self._load_dl_model()
        
    def _load_dl_model(self):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ (KR-FinBert-SC)"""
        if not TRANSFORMERS_AVAILABLE:
            print("[WARNING] transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.use_deep_learning = False
            return

        try:
            print("[INFO] ë”¥ëŸ¬ë‹ ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘... (snunlp/KR-FinBert-SC)")
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            device = 0 if torch.cuda.is_available() else -1
            
            # íŒŒì´í”„ë¼ì¸ ìƒì„±
            self.dl_pipeline = pipeline(
                "sentiment-analysis",
                model="snunlp/KR-FinBert-SC",
                tokenizer="snunlp/KR-FinBert-SC",
                device=device
            )
            print(f"[INFO] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: {'GPU' if device==0 else 'CPU'})")
        except Exception as e:
            print(f"[ERROR] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.use_deep_learning = False

    def analyze_text_llm(self, text: str) -> tuple:
        """
        LLM(Gemini) ê¸°ë°˜ ê°ì„± ë¶„ì„
        
        Returns:
            tuple: (ì ìˆ˜, ìƒì„¸ì •ë³´ dict)
        """
        if not self.llm_analyzer:
            return self.analyze_text(text)
        
        try:
            result = self.llm_analyzer.analyze(text)
            # SentimentResult ì†ì„±: score, confidence, source, keywords
            return result.score, {
                'keywords': result.keywords,
                'confidence': result.confidence,
                'source': result.source
            }
        except Exception as e:
            print(f"[WARNING] LLM ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {e}. ê¸°ë³¸ ë¶„ì„ ì‚¬ìš©.")
            return self.analyze_text(text)

    def analyze_text(self, text: str) -> tuple:
        """ê¸°ë³¸ ê°ì„± ë¶„ì„ (í‚¤ì›Œë“œ/TextBlob) - í•œêµ­ì–´ìš©"""
        score = self.analyze_sentiment(text)
        return score, {}

    def analyze_text_en(self, text: str) -> tuple:
        """ì˜ë¬¸ í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„ (VADER ê¸°ë°˜)"""
        if not text:
            return 0.0, {}
        
        try:
            # VADER ë¶„ì„ê¸° ì‚¬ìš© (ì˜ë¬¸ì— ìµœì í™”)
            if self.vader_analyzer:
                scores = self.vader_analyzer.polarity_scores(text)
                # compound ì ìˆ˜: -1.0 ~ 1.0
                compound = scores['compound']
                
                # ë ˆì´ë¸” ê²°ì •
                if compound >= 0.05:
                    label = 'positive'
                elif compound <= -0.05:
                    label = 'negative'
                else:
                    label = 'neutral'
                
                return compound, {
                    'label': label,
                    'positive': scores['pos'],
                    'negative': scores['neg'],
                    'neutral': scores['neu']
                }
            
            # VADER ì‚¬ìš© ë¶ˆê°€ ì‹œ TextBlob í´ë°±
            elif TEXTBLOB_AVAILABLE:
                blob = TextBlob(text)
                polarity = blob.sentiment.polarity
                
                if polarity > 0.1:
                    label = 'positive'
                elif polarity < -0.1:
                    label = 'negative'
                else:
                    label = 'neutral'
                    
                return polarity, {'label': label}
            
            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ 0 ë°˜í™˜
            return 0.0, {'label': 'neutral'}
            
        except Exception as e:
            print(f"[ERROR] ì˜ë¬¸ ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.0, {'label': 'neutral'}

    def analyze_text_deep(self, text: str) -> tuple:
        """ë”¥ëŸ¬ë‹ ê°ì„± ë¶„ì„"""
        if not self.use_deep_learning or not self.dl_pipeline:
            return self.analyze_text(text)
            
        try:
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (FinBERTëŠ” 512 í† í° ì œí•œ)
            # ëŒ€ëµì ì¸ ë¬¸ì ìˆ˜ë¡œ ìë¦„ (í† í¬ë‚˜ì´ì € ì†ë„ ìµœì í™”)
            if len(text) > 1000:
                text = text[:1000]
                
            result = self.dl_pipeline(text)[0]
            # result ì˜ˆì‹œ: {'label': 'positive', 'score': 0.99}
            # KR-FinBert-SC labels: positive, negative, neutral
            
            label = result['label']
            confidence = result['score']
            
            # ì ìˆ˜ ë³€í™˜ (-1.0 ~ 1.0)
            score = 0.0
            if label == 'positive':
                score = confidence
            elif label == 'negative':
                score = -confidence
            else: # neutral
                score = 0.0
                
            return score, {'label': label, 'confidence': confidence}
            
        except Exception as e:
            print(f"[ERROR] ë”¥ëŸ¬ë‹ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self.analyze_text(text)
        
    def analyze_sentiment(self, text: str) -> float:
        """
        í…ìŠ¤íŠ¸ì˜ ê°ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            -1.0 (ë¶€ì •) ~ 1.0 (ê¸ì •) ì‚¬ì´ì˜ ì‹¤ìˆ˜
        """
        if not text:
            return 0.0
            
        # 1. í…ìŠ¤íŠ¸ ì •ì œ
        clean_text = self._clean_text(text)
        
        # 2. TextBlobì„ ì´ìš©í•œ ê¸°ì´ˆ ë¶„ì„ (ì˜ì–´ì— ê°•í•¨)
        score = 0.0
        if TEXTBLOB_AVAILABLE:
            try:
                blob = TextBlob(clean_text)
                score = blob.sentiment.polarity
            except:
                pass
        
        # 3. í•œêµ­ì–´ ê¸ˆìœµ í‚¤ì›Œë“œ ë³´ì • (ê°„ë‹¨í•œ ê·œì¹™)
        # TextBlobì€ í•œêµ­ì–´ ì§€ì›ì´ ì•½í•˜ë¯€ë¡œ, ëª…ì‹œì ì¸ í‚¤ì›Œë“œë¡œ ì ìˆ˜ ë³´ì •
        korean_score = self._analyze_korean_keywords(clean_text)
        
        # ì˜ì–´ ë¶„ì„ ê²°ê³¼ì™€ í•œêµ­ì–´ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ê²°í•©
        # í•œêµ­ì–´ í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ë©´ ìš°ì„ ìˆœìœ„ë¥¼ ë‘ 
        if korean_score != 0:
            final_score = (score + korean_score) / 2
            # ë²”ìœ„ ì œí•œ
            return max(-1.0, min(1.0, final_score))
            
        return score
    
    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ"""
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì¼ë¶€ ë³´ì¡´)
        text = re.sub(r'[^\w\s\.\,\%\-\+]', ' ', text)
        return text.strip()
        
    def _analyze_korean_keywords(self, text: str) -> float:
        """í•œêµ­ì–´ ê¸ˆìœµ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        positive_keywords = [
            'ìƒìŠ¹', 'ê¸‰ë“±', 'ìµœê³ ê°€', 'í˜¸ì¬', 'ì„±ì¥', 'ì´ìµ', 'ìˆ˜ìµ', 'ê°œì„ ', 'ëŒíŒŒ', 
            'ë§¤ìˆ˜', 'ê¸ì •', 'ê¸°ëŒ€', 'í™•ëŒ€', 'íšŒë³µ', 'ê°•ì„¸', 'ì²´ê²°', 'ìˆ˜ì£¼', 'ë°°ë‹¹'
        ]
        negative_keywords = [
            'í•˜ë½', 'ê¸‰ë½', 'ìµœì €ê°€', 'ì•…ì¬', 'ì†ì‹¤', 'ì ì', 'ê°ì†Œ', 'ì´íƒˆ', 
            'ë§¤ë„', 'ë¶€ì •', 'ìš°ë ¤', 'ì¶•ì†Œ', 'ë‘”í™”', 'ì•½ì„¸', 'í•´ì§€', 'ì·¨ì†Œ', 'ë¶ˆí™•ì‹¤'
        ]
        
        score = 0.0
        for word in positive_keywords:
            if word in text:
                score += 0.3
        
        for word in negative_keywords:
            if word in text:
                score -= 0.3
                
        return max(-1.0, min(1.0, score))

    def analyze_news_list(self, news_list: List[Dict]) -> List[Dict]:
        """
        ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ë¶„ì„í•˜ì—¬ ì ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            news_list: ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê°ì„± ì ìˆ˜ê°€ ì¶”ê°€ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        for news in news_list:
            # ì œëª©ê³¼ ë³¸ë¬¸ì„ í•©ì³ì„œ ë¶„ì„ ê°€ì¤‘ì¹˜ ì¡°ì ˆ
            title = news.get('title', '')
            content = news.get('content', '')
            
            # ì œëª©ì— ê°€ì¤‘ì¹˜ 2ë°°
            full_text = f"{title} {title} {content}"
            sentiment = self.analyze_sentiment(full_text)
            
            news['sentiment_score'] = sentiment
            news['sentiment_label'] = 'positive' if sentiment > 0.1 else ('negative' if sentiment < -0.1 else 'neutral')
            
        return news_list